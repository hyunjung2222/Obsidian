### 문제 인식
- 정확성과 속도 모두 높은 머신러닝 모델을 개발하자
# 1. 학습 데이터 준비
- 머신러닝 모델의 목적에 맞춰서 학습 데이터를 준비
- Data 수집, Data 유형에 따른 처리, Data stamping, labeling
1.  수집 방법 설계
	- 데이터를 수집하여 데이터셋 구성을 설계
	- 어떤 데이터를 수집하는 등의 프로토콜 설계
2. 개인 정보 보호 검토
3. 데이터 수집
	- 크롤링을 통해 수집할 경우, 저장할 스토리지와 어떤 스토리지 유형을 선택할지를 고려
4. 레이블링(정답셋)
	- 없는 경우, 어떻게 이 문제를 해결할지 검토 필요
### 데이터 샘플링
- 큰 데이터 집합에서 작은 부분 집합을 추출하는 프로세스
- 전체 데이터셋에 대한 통찰력을 얻거나 계산/저장 공간을 줄이는 데 도움
- 목적: 자원 및 시간 절약, 품질 향상, 통계적 추론, 데이터 시각화, 데이터 테스트
1. random sampling
2. strarified sampling
3. weigth sampling
4. importance sampling
## Semi-supervised Learning 방법론
### Self Training
- 초기에 Labeling된 데이터로 모델을 훈련한 후, 모델이 높게 예측한 Labeling 없는 데이터에 적용하여 Labeling을 하고 모델을 학습하는 과정을 반복
### Co Training
- 데이터를 여러 독립적인 부분 집합 또는 도메인으로 나누어 모델을 학습하여, semi-supervised 학습에서의 데이터 부족 문제를 해결
### Multi view Learning
- 데이터를 여러 다른 관점 또는 특성을 나누어 모델을 학습
- 데이터의 다양한 특성이 중요한 경우에 유용
## Self-supervised Learning
- Labeling된 데이터 없이도 모델을 훈련시키는 학습법
- 데이터 내에서 숨겨진 정보를 활용하여 모델을 학습
### Auto Encoder
- 입력 데이터를 압축하고 다시 복원하는 네트워크 아케텍처로, encoder와 decoder로 구성
- 모델은 입력 데이터를 압축하고 복원하는 과정에서 정보를 학습
### Masked Language Model
- 일부 단어를 가리고 해당 단어를 예측하는 Task를 활용
- 모델은 문맥을 이해하고 숨겨진 단어를 예측하기 위해 단어 간의 관계를 학습
- 자연어 처리 모델의 사전 훈련에 많이 쓰임
### Contrastive Learning
- 모델에서 유사한 데이터를 가깝게, 다른 데이터는 멀게 표현하도록 학습시키는 방법
## 일반적인 모델 학습 유형
### Transfer Learning
- 이미 훈련된 모델을 다른 작업에 적용하는 방법
- 사전 훈련된 모델은 대용량 데이터로 학습되어 다양한 특징을 추출하고, 이를 새로운 작업에 Transfer하는 데 사용
### Fine Tuning
- Transfer Learning의 한 형태로, 사전 학습된 모델을 새로운 작업에 맞게 미세 조정하는 과정
- ex. GPT와 같은 모델에 자체적인 문서 분류, 감정 분석 데이터에 추가 학습시켜서 활용
### Online Learning
- 데이터를 순차적으로 처리하면서 모델을 업데이트하는 방식
- 새로운 데이터가 도착할 때마다 모델은 finetune하며, 스트리밍 데이터나 지속적인 학습을 위해 유용
###  Batch Learning
- 데이터셋을 한번에 모델에 입력하는 전통적인 방식
## Resampling
### OverSampling
1. SMOTE
	1. 소수 클래스 데이터 포인트들을 기존 데이터를 활용하여 데이터를 균형화하는 방법
2. ADASYN
	1. 소수 클래스 데이터 포인트들을 기존 데이터를 활용하여 데이터를 균형화하는 방법
	2. 소수 클래스 데이터 포인트의 가중치를 계산하고 높은 가중치를 가지는 데이터 포인트에 대해 더 많은 합성을 수행
# 2. Feature Engineering
- 데이터를 모델에 학습할 수 있는 형태로 Engineering
- Data Cleansing, Feature Selection, Feature Reduction, Data Augmentation, Data Scaling & Encoding
1. 데이터 정제 및 결측치 처리
2. 데이터 분석
3. 변환 및 스케일링
4. 데이터 분할 및 검증 세트 구성
# 3. 모델 학습 및 최적화 평가
- 모델을 목적에 맞게 학습하고 평가, 최적화
- Model Training, Model Evaluation, Model Hyperparameter Tuning
### 모델 훈련과 선택
1. 여러가지 머신러닝 알고리즘 검토
	- 선형 회귀, 의사결정 트리, 랜덤 포레스트, SVM 등 다양한 알고리즘 검토
2. 모델 선택 프로세스
	- 평가 지표를 설정하고 검증 세트를 사용하여 여러가지 알고리즘의 성능을 비교
	- 최종 모델을 선택하고 훈련
3. 모델 훈련 및 성능 평가
	- 모델을 훈련하면서 하이퍼파라미터를 조정하며, 다양한 평가 지표를 활용하여 검증 세트에 대한 예측 성능을 평가
### 모델 성능 향상, 최적화
1. 하이퍼파라미터 튜닝
	1. 그리드 탐색, 랜덤 탐색, 베이지안 최적화 등의 방법을 사용
2. 앙상블 기법
	1. 다양한 알고리즘의 결과를 결합하여, 보다 정확한 예측이 가능한지 테스트
3. 오차 분석 및 해결
	1. 모델이 잘못 예측한 샘플에 대한 오차를 분석하여, 모델 성능을 개선할 수 있는 방법을 모색
# 모델 상품화 검토
- 성능 평가 결과
- 성능 개선의 가능성
- 적용 가능한지 검토

-------
