[# Machine Learning Operations (MLOps): Overview, Definition, and Architecture](https://arxiv.org/abs/2205.02302)


#CI/CD #DevOps #Machine_Learning #MLOps #Operations #Workflow_Orchestration

>[!초록] 
>모든 산업적 ML 프로젝트의 궁극적인 목표는 ML 제품을 개발하고 이를 신속하게 프로덕션에 도입하는 것임.
>하지만, ML 제품을 자동화하고 운영하는 것은 매우 어려운 과제임.
>머신러닝 운영(MLOps) 패러다임은 이러한 문제를 해결하기 위한 접근 방식임.
>MLOps는 모범 사례, 개념적 요소, 개발 문화 등 여러 측면을 포함함.
>그러나 MLOps는 아직 모호한 개념이며, 연구자와 실무자에게 미치는 영향도 불분명함.
>이러한 간극을 해소하기 위해 본 연구에서는 문헌 조사, 도구 검토, 전문가 인터뷰를 포함한 혼합 연구 방법을 수행함.
>이를 통해, 
>1. MLOps 에 필요한 원칙, 구성 요소, 역할뿐만 아니라 관련된 아키텍처와 워크플로우에 대한 종합적인 개요 제공
>2. MLOps의 정의를 제시하고 이 분야의 주요 도전 과제를 강조
>3. 특정 기술 세트를 활용하여 ML 제품을 자동화하고 운영하는 데 필요한 지침 제공

### 내가 이해하기 위한 용어 간단 정리
- production
	- 실제 사용자가 접근할 수 있는 상태로 배포된 단계
	- 개발된 머신러닝 모델이나 소프트웨어가 실제 사용자들이 사용하는 환경에서 운영되는 상태
# 1. Introduction
많은 ML 애플리케이션이 기대에 미치지 못한 경우가 많은데, 그 이유가
1. ML 커뮤니티가 주로 ML 모델 구축에 집중해왔기 때문이며
2. (a) 프로덕션 수준의 ML 제춤을 개발하는 것과 (b) 실제 환경에서 ML 시스템을 자동화하고 운영하는 데 필요한 다양한 구성 요소 및 인프라, 그리고 역할을 조율하는 것에는 상대적으로 관심이 부족했기 때문

예를 들어, 데이터 과학자들이 여전히 ML 워크플로우를 수동으로 관리하고 있음
-> 이를 해결하기 위해 본 연구의 목표는 <u>수동으로 이루어지는 ML 프로세스를 자동화하고 운영할 수 있는 방안을 분석하여, 보다 많은 ML 개념 증명이 프로덕션 환경으로 이전될 수 있도록 하는 것</u>

RQ(Research Question): What is MLOps?
이 질문에 답하기 위해 혼합 연구 방법론을 적용하여 다음을 분석
- MLOps의 주요 원칙을 도출
- 기능적 핵심 구성 요소를 정리
- 성공적인 MLOps 구현을 위해 필요한 역할을 조명
- ML 시스템 설계를 위한 일반적인 아키텍처를 도출함

# 2. Foundations of DevOps
- DevOps
	- 2008/2009년경에 이 개념이 등장함
	- 소프트웨어 개발 과정에서 발생하는 문제를 줄이는 것을 목표로 함
	- 단순한 방법론이 아닌, 조직 내에서 발생하는 사회적, 기술적 문제를 해결하는 패러다임
	- 핵심목표: 개발과 운영 간의 격차를 해소하는 것
	- 협업, 커뮤니케이션, 지식 공유를 강조
		- 지속적 통합(CI), 지속적 제공(CD), 지속적 배포(CD)를 자동화를 보장함으로써 빠르고 빈번하며 신뢰할 수 있는 소프트웨어 릴리스를 가능하게 함
	
- 다양한 DevOps 도구도 등장. 여섯 개의 주요 그룹으로 분류할 수 있음
	- 협업 및 지식 공유 (예: Slack, Trello, GitLab 위키)
	- 소스 코드 관리 (예: GitHub, GitLab)
	- 빌드 프로세스 (예: Maven)
	- 지속적 통합 (예: Jenkins, GitLab CI)
	- 배포 자동화 (예: Kubernetes, Docker)
	- 모니터링 및 로깅 (예: Prometheus, Logstash)
# 3. Methodology
혼합 연구 방법을 적용 (그림1 참조)
![[MLOpsOverviewof_the_methodology.png | 500]]

## 3.1 Literature Review
- non-peer-reviewed 문헌도 포함
- 2021년 5월에 학술 데이터베이스를 검색, 총 1864개의 논문 찾음, 최종적으로 27편을 연구에 포함
## 3.2 Tool Review
- 관련 도구의 개요는 부록의 Table1에 정리되어 있음
## 3.3 Interview Study
- 반구조화된 전문가 인터뷰를 수행함
- 전문가 인터뷰 연구 설계에서 중요한 요소 중 하나는 적절한 샘플 크기 선택 -> 우리는 이론적 샘플링 접근법을 적용
- Linkedin에서 ML 전문가를 식별하여 interview saturation 진행
# 4. Results
- 앞서 설명한 방법론을 적용하여, MLOps의 핵심 원칙, 이를 구체화하는 구성 요소, 필요한 역할 그리고 이러한 요소들을 조합하여 도출된 아키텍처 및 워크플로우를 제안함
- 마지막으로, MLOps 개념을 정립하고 이에 대한 정의를 제공함
## 4.1 Principles
- 연구를 통해 MLOps를 실현하는 데 필요한 9가지 원칙을 도출함
- Figure 2는 이 원칙들을 시각화하고 각각이 어떤 구성 요소와 연결되는지를 보여줌
- CI/CD 자동화, 워크플로우 오케스트레이션, 재현성, 버전관리, 협업, 지속적인 ML학습 및 평가, ML 메타데이터 추적 및 로깅, 지속적 모니터링, 피드백 루프
![[MLOpsPrinciples.png | 600]]
## 4.2 Technical Components
1. CI/CD 구성 요소
	1. 빌드, 테스트, 제공, 배포 단계를 담당
	2. 특정 단계의 성공 또는 실패 여부를 개발자에게 빠르게 피드백하여 전체 생산성을 높임
	3. ex. Jenkins, GitHub Actions
2. 소스 코드 저장소
	1. 코드 저장과 버전 관리를 보장
	2. ex. Bitbucket, GitLab, GitHub
3. 워크플로우 오케스트레이션 구성 요소
	1. DAG(유향 비순환 그래프)를 사용하여 ML 워크플로우의 태스크를 오케스트레이션을 함
	2. DAG는 실행 순서와 각 단계에서 사용하는 아티팩트를 나타냄
	3. ex. Apache Airflow, Kubeflow Pipelines, AWS SageMaker Pipelines
4. 피처 저장소 시스템
	1. 공통적으로 사용되는 피처를 중앙에서 관리함
	2. 두 개의 데이터베이스로 구성
		1. 실험용으로 보통 지연 시간을 가지는 오프라인 저장소
		2. 프로덕션 환경에서 예측을 수행하기 위한 저지연 온라인 저장소
	3. ex. Google Feast, Amazon AWS Feature Store
5. 모델 학습 인프라
	1. 분산 또는 비분산 형태일 수 있으며, 일반적으로 확장 
	2. ex. Kubernetes, Red Hat OpenShift
6. 모델 레지스트리
	1. 학습된 ML 모델과 해당 메타데이터를 중앙에서 저장.
	2. 주요 기능: ML 아티팩트 저장 및 ML 메타데이터 저장
	3. ex. (고급 저장소)MLflow, AWS SageMaker (간단한 저장소) Microsoft Azure Storage, Google Cloud Storage, Amazon AWS S3
7. ML 메타데이터 저장소
	1. ML 워크플로우 파이프라인의 각 태스크에서 발생하는 다양한 메타데이터를 추적할 수 있도록 함.
	2. 또 다른 메타데이터 저장소는 모델 레지스트리 내부에 구성되어 각 학습 작업의 메타데이터, 모델 관련 메타데이터를 기록할 수 있음
	3. ex. Kubeflow Pipelines, AWS SageMaker Pipelines
8. 모델 서빙 구성 요소
	1. 다양한 목적에 맞게 설정 가능 (예: 온라인 추론, 배치 추론 등)
	2. 서빙은 REST API 등을 통해 제공될 수 있음.
	3. 기본 인프라 계층으로 확장 가능하고 분산된 모델 서빙 인프라를 권장함
	4. ex. Kubernetes와 Docker를 사용한 ML 모델 컨테이너화 및 Flask를 이용한 REST API 기반 서빙
		1. 기타 Kubernetes 지원 프레임워크: Kubeflow KServing
		2. 배치 예측을 위한 프레임워크: Apache Spark
		3. 클라우드 기반 서빙: Microsoft Azure ML REST API, AWS SageMaker Endpoints...
9. 모니터링 구성 요소
	1. 모델 서빙 성능의 지속적인 모니터링을 담당
	2. ML 인프라, CI/CD, 오케스트레이션의 모니터링
	3. ex. Prometheus + Gragana, ELK 스택, TensorBoard
		1. 내장 모니터링 기능이 있는 예시: Kubeflow, MLflow, AWS SageMaker Model Monitor 및 CloudWatch
## 4.3 Roles
![[MLOpsRoles.png | 400]]
- MLOps는 다양한 분야가 협력하는 프로세스로, 서로 다른 역할 간의 상호 작용이 ML 시스템을 설계, 관리, 자동화, 운영하는 데 필수적
- 다음은 각 역할, 그 목적, 관련된 주요 업무에 대한 간략한 설명임
1. 비즈니스 이해관계자
	1. ML을 통해 달성할 비즈니스 목표를 정의하고 비즈니스 관점에서의 커뮤니케이션을 담당
2. 솔루션 아키텍트
	1. 시스템 아키텍처를 설계하고 사용할 기술을 평가하여 결정하는 역할
3. 데이터 사이언티스트
	1. 비즈니스 문제를 ML 문제로 변환하고 모델 엔지니어링을 담당하며, 최적의 알고리즘과 하이퍼파리미터를 선택하는 역할
4. 데이터 엔지니어
	1. 데이터 및 피처 엔지니어링 파이프라인을 구축하고 관리하는 역할
	2. 피처 저장소 시스템의 데이터베이스로 적절하게 데이터를 수집할 수 있도록 보장
5. 소프트웨어 엔지니어
	1. 소프트웨어 설계 패턴, 널리 받아들여진 코딩 가이드라인, 베스트 프랙티스를 적용하여 ML 문제를 체계적으로 구축된 제품으로 변환하는 역할
6. DevOps 엔지니어
	1. 개발과 운영 간의 격차를 해소하는 역할을 하며, CI/CD 자동화, ML 워크플로우 오케스트레이션, 모델 배포, 모니터링을 보장함
7. ML 엔지니어 / MLOps 엔지니어
	1. ML 인프라를 구축 및 운영하고, 자동화된 ML 워크플로우 파이프라인을 관리
	2. 모델을 프로덕션 환경에 배포
	3. 모델 및 ML 인프라를 모니터링하는 업무를 수행
# 5. Architecture and Workflow
![[MLOPsArchitecture&Workflow.png]]

- 위 사진은 일반적인 End-to-end MLOps 아키텍처. 다양한 단계에서 수행되는 작업들의 순서를 포함한 워크플로우도 함께 제시됨.
- MLOps 프로젝트 기획부터 모델 서빙까지 포함하며, 다음과 같은 네 단계로 구성됨
	- (A) MLOps 프로젝트 기획 (B) 피처 엔지니어링 파이프라인(데이터 수집 및 피처 저장소 적재 포함)
	- (C) 실험 과정 (D) 자동화된 ML 워크플로우 파이프라인 및 모델 서빙
### (A) MLOps 프로젝트 기획
1. 비지니스 이해관계자: 비즈니스 분석을 수행하고, ML을 활용해 해결할 수 있는 비즈니스 문제를 도출
2. 솔루션 아키텍트: 전체 ML 시스템의 아키텍처를 설계하고, 철저한 평가 후 사용할 기술을 결정함
3. 데이터 사이언티스트: 비즈니스 목표를 ML 문제로 변환한다. 
4. 데이터 엔지니어 & 데이터 사이언티스트: 문제 해결에 필요한 데이터를 파악하기 위해 협업한다.
5. 데이터 엔지니어 & 데이터 사이언티스트: 원시 데이터 소스를 찾고, 데이터 분포 및 품질을 분석하며, 검증 작업을 수행. 들어오는 데이터가 라벨링되어 있는지 확인(이는 지도 학습을 위한 필수 조건)
### (B1) 피처 엔지니어링 파이프라인 요구사항 정의
- 피처는 모델 학습을 위해 필요한 핵심 속성
6. 데이터 엔지니어: 데이터를 활용할 수 있도록 변환 규칙 및 데이터 정제 규칙을 정의함
7. 데이터 사이언티스트 & 데이터 엔지니어: 기존 피처를 활용하여 새로운 피처를 계산하는 규칙을 정의함
### (B2) 피처 엔지니어링 파이프라인 구축
- 정의된 요구사항을 기반으로 데이터 엔지니어와 소프트웨어 엔지니어가 피처 엔지니어링 파이프라인의 프로토타입을 구축함
8. 피처 엔지니어링 파이프라인이 원시 데이터에 연결됨
9. 데이터 소스로부터 데이터를 추출함.
10. 데이터 전처리 수행: 데이터 변환 및 정제 작업이 진행됨
11. 피처 엔지니어링 수행: 기존 피처를 활용해 새로운 피처를 생성함
12. 데이터 적재: 배치 또는 스트리밍 데이터가 피처 저장소 시스템에 저장됨
### (C) 실험 과정
- 실험 단계의 주요 작업은 데이터 사이언티스트가 주도하며, 소프트웨어 엔지니어가 지원함
13. 데이터 사이언티스트는 피처 저장소 시스템에 연결하여 데이터를 분석함
14. 피처 저장소에서 가져온 데이터를 준비 및 검증하는 과정이 필요함
15. 모델 훈련 및 하이퍼파라미터 튜닝
16. 반복적인 모델 훈련 및 검증: 최종 목표는 최상의 성능을 내는 알고리즘과 하이퍼파라미터 조합을 찾는 것
17. 모델 내보내기 및 코드 커밋
- DevOps 엔지니어 또는 ML 엔지니어는 자동화된 ML 워크플로우 파이프라인을 위한 코드를 정의하고, 이를 저장소에 커밋함
	- CI/CD 파이프라인 자동 실행
	- CI/CD 파이프라인의 주요 단계
		- 빌드: ML 모델과 ML 워크플로우 파이프라인의 각 작업을 포함하는 아티팩트를 생성
		- 테스트: ML 모델과 ML 워크플로우 파이프라인 코드의 유효성을 검증함
		- 배포: 버전이 지정된 아티팩트를 아티팩트 저장소에 푸시함
### (D) 자동화된 ML 워크플로우 파이프라인 및 모델 서빙
- 관리 및 인프라 설정
	- DevOps & ML 엔지니어가 자동화된 ML 워크플로우 파이프라인을 관리함
	- ML 훈련을 위한 하드웨어 리소스 및 연산 프레임워크(쿠버네티스 등)도 관리함
- 워크플로우 오케스트레이션
	- 워크플로우 오케스트레이션 컴포넌트가 자동화된 ML 워크플로우 파이프라인의 각 작업을 조정함
	- 각 작업은 컨테이너 등 격리된 환경에서 실행될 수 있음
18. 데이터 추출: 버전이 지정된 피처 데이터를 피처 저장소 시스템에서 자동으로 가져옴
19. 데이터 준비 및 검증
20. 자동 모델 훈련: 이전 실험 단계에서 결정된 알고리즘 및 하이퍼파라미터 설정을 사용하여 새로운 데이터로 모델을 자동 훈련함
21. 모델 평가 및 하이퍼파라미터 조정
22. 모델 내보내기
23. 모델 등록: 내보낸 모델을 모델 레지스트리에 저장함
24. 모델 배포 자동화: 성능이 충분히 검증된 모델이 스테이징에서 프로덕션으로 변경되면 DevOps 엔지니어 또는 ML 엔지니어가 모델을 배포함.
	1. 이 과정에서 CI/CD 컴포넌트가 지속적 배포 파이프라인을 실행함
25. 모델 서빙: 보통 컨테이너 환경에서 이루어지며, 예측 요청은 REST API를 통해 처리됨
26. 모델 모니터링: 예를 들어, 예측 정확도가 낮아지면 이를 감지하여 경고를 보냄
27. 피드백 루프: 모니터링 컴포넌트에서 이상 징후가 감지되면, 피드백을 전송
28. 연속 학습 및 개념 드리프트 탐지: 모델이 배포된 후에도 지속적인 훈련이 필요할 수 있음

### 정리
이 자동화된 ML 파이프라인은 데이터 수집부터 모델 배포 및 유지 보수까지 전체 ML 라이프사이클을 관리하는 구조다.
- 자동화된 데이터 추출, 모델 학습, 평가, 배포 및 모니터링
- 모델 서빙을 위한 실시간 또는 배치 예측 지원
- 모델 성능 저하 감지 및 개념 드리프트 대응을 위한 피드백 루프
- CI/CD와 연계하여 지속적인 개선 및 재학습 수행
이 과정 덕분에 ML 모델이 끊임없이 개선되고, 프로덕션 환경에서 최적의 성능을 유지할 수 있다.

# 6. Conceptualization
- 문헌 연구와 인터뷰 결과를 종합하면, **MLOps는 머신러닝, 소프트웨어 엔지니어링, DevOps, 데이터 엔지니어링이 교차하는 지점**에 위치함
- MLOp란?
	- **ML 제품의 전체 수명 주기**(설계, 구현, 모니터링, 배포, 확장성 관리)를 위한 **패러다임**
	- 단순한 도구나 프레임워크가 아닌, 모범 사례, 개념적 접근법, 개발 문화를 포함함
	- 세 가지 핵심 분야를 결합함
		- 머신러닝 / 소프트웨어 엔지니어링(특히 DevOps 포함) / 데이터 엔지니어링
- MLOps 의 목표
	- 머신러닝 시스템을 프로덕션 환경에 안정적으로 배포하고 운영할 수 있도록 지원함
	- 개발(Dev)와 운영(Ops)의 간극을 해소하여 ML 제품을 보다 원활하게 구축하도록 돕는다.
- MLOps의 핵심 원칙
	- CI/CD 자동화 (지속적 통합 및 배포)
	- 워크플로우 오케스트레이션 (자동화된 ML 파이프라인)
	- 재현성
	- 데이터, 모델, 코드의 버전 관리
	- 협업
	- 연속적인 ML 훈련 및 평가
	- ML 메타데이터 추적 및 로깅
	- 지속적인 모니터링
	- 피드백 루프 활용
- 즉, **MLOps는 머신러닝 모델을 프로덕션 환경에서 효과적으로 운영하고 개선하기 위한 종합적인 엔지니어링 접근법이다**.

# 7. Open Challenges
- MLOps는 머신러닝 모델을 프로덕션 환경에서 원활히 운영할 수 있도록 돕는 강력한 접근 방식이지만, **조직적, 기술적, 운영적 측면에서 해결해야 할 과제가 많음.**
- 특히, **조직의 협업 문화 변화, 자동화된 운영 체계 구축, 모델과 데이터의 체계적인 관리**가 중요함.
# 8. Conclusion
- 학계에서는 머신러닝 모델 개발과 성능 벤치마킹에 집중해왔지만, 복잡한 머신러닝 시스템을 실제 환경에서 운영하는 문제에 대한 연구는 부족한 상황임
- MLOps의 4가지 핵심 요소(원칙, 구성요소, 역할, 아키텍처)를 도출하였고 이를 기반으로 MLOps의 총체적인 정의를 제시함.
- 이 연구 결과는 MLOps 개념과 관련 요소에 대한 공통된 이해를 정립하는 데 기여할 것이고, 향후 연구자와 실무자가 성공적인 ML 프로젝트를 구축하는 데 도움을 줄 것으로 기대함.
