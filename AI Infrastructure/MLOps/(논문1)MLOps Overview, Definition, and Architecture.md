[# Machine Learning Operations (MLOps): Overview, Definition, and Architecture](https://arxiv.org/abs/2205.02302)


#CI/CD #DevOps #Machine_Learning #MLOps #Operations #Workflow_Orchestration

>[!초록] 
>모든 산업적 ML 프로젝트의 궁극적인 목표는 ML 제품을 개발하고 이를 신속하게 프로덕션에 도입하는 것임.
>하지만, ML 제품을 자동화하고 운영하는 것은 매우 어려운 과제임.
>머신러닝 운영(MLOps) 패러다임은 이러한 문제를 해결하기 위한 접근 방식임.
>MLOps는 모범 사례, 개념적 요소, 개발 문화 등 여러 측면을 포함함.
>그러나 MLOps는 아직 모호한 개념이며, 연구자와 실무자에게 미치는 영향도 불분명함.
>이러한 간극을 해소하기 위해 본 연구에서는 문헌 조사, 도구 검토, 전문가 인터뷰를 포함한 혼합 연구 방법을 수행함.
>이를 통해, 
>1. MLOps 에 필요한 원칙, 구성 요소, 역할뿐만 아니라 관련된 아키텍처와 워크플로우에 대한 종합적인 개요 제공
>2. MLOps의 정의를 제시하고 이 분야의 주요 도전 과제를 강조
>3. 특정 기술 세트를 활용하여 ML 제품을 자동화하고 운영하는 데 필요한 지침 제공

### 내가 이해하기 위한 용어 간단 정리
- production
	- 실제 사용자가 접근할 수 있는 상태로 배포된 단계
	- 개발된 머신러닝 모델이나 소프트웨어가 실제 사용자들이 사용하는 환경에서 운영되는 상태
# 1. Introduction
많은 ML 애플리케이션이 기대에 미치지 못한 경우가 많은데, 그 이유가
1. ML 커뮤니티가 주로 ML 모델 구축에 집중해왔기 때문이며
2. (a) 프로덕션 수준의 ML 제춤을 개발하는 것과 (b) 실제 환경에서 ML 시스템을 자동화하고 운영하는 데 필요한 다양한 구성 요소 및 인프라, 그리고 역할을 조율하는 것에는 상대적으로 관심이 부족했기 때문

예를 들어, 데이터 과학자들이 여전히 ML 워크플로우를 수동으로 관리하고 있음
-> 이를 해결하기 위해 본 연구의 목표는 <u>수동으로 이루어지는 ML 프로세스를 자동화하고 운영할 수 있는 방안을 분석하여, 보다 많은 ML 개념 증명이 프로덕션 환경으로 이전될 수 있도록 하는 것</u>

RQ(Research Question): What is MLOps?
이 질문에 답하기 위해 혼합 연구 방법론을 적용하여 다음을 분석
- MLOps의 주요 원칙을 도출
- 기능적 핵심 구성 요소를 정리
- 성공적인 MLOps 구현을 위해 필요한 역할을 조명
- ML 시스템 설계를 위한 일반적인 아키텍처를 도출함

# 2. Foundations of DevOps
- DevOps
	- 2008/2009년경에 이 개념이 등장함
	- 소프트웨어 개발 과정에서 발생하는 문제를 줄이는 것을 목표로 함
	- 단순한 방법론이 아닌, 조직 내에서 발생하는 사회적, 기술적 문제를 해결하는 패러다임
	- 핵심목표: 개발과 운영 간의 격차를 해소하는 것
	- 협업, 커뮤니케이션, 지식 공유를 강조
		- 지속적 통합(CI), 지속적 제공(CD), 지속적 배포(CD)를 자동화를 보장함으로써 빠르고 빈번하며 신뢰할 수 있는 소프트웨어 릴리스를 가능하게 함
	
- 다양한 DevOps 도구도 등장. 여섯 개의 주요 그룹으로 분류할 수 있음
	- 협업 및 지식 공유 (예: Slack, Trello, GitLab 위키)
	- 소스 코드 관리 (예: GitHub, GitLab)
	- 빌드 프로세스 (예: Maven)
	- 지속적 통합 (예: Jenkins, GitLab CI)
	- 배포 자동화 (예: Kubernetes, Docker)
	- 모니터링 및 로깅 (예: Prometheus, Logstash)
# 3. Methodology
혼합 연구 방법을 적용 (그림1 참조)
![[MLOpsOverviewof_the_methodology.png | 500]]

## 3.1 Literature Review
- non-peer-reviewed 문헌도 포함
- 2021년 5월에 학술 데이터베이스를 검색, 총 1864개의 논문 찾음, 최종적으로 27편을 연구에 포함
## 3.2 Tool Review
- 관련 도구의 개요는 부록의 Table1에 정리되어 있음
## 3.3 Interview Study
- 반구조화된 전문가 인터뷰를 수행함
- 전문가 인터뷰 연구 설계에서 중요한 요소 중 하나는 적절한 샘플 크기 선택 -> 우리는 이론적 샘플링 접근법을 적용
- Linkedin에서 ML 전문가를 식별하여 interview saturation 진행
# 4. Results
- 앞서 설명한 방법론을 적용하여, MLOps의 핵심 원칙, 이를 구체화하는 구성 요소, 필요한 역할 그리고 이러한 요소들을 조합하여 도출된 아키텍처 및 워크플로우를 제안함
- 마지막으로, MLOps 개념을 정립하고 이에 대한 정의를 제공함
## 4.1 Principles
- 연구를 통해 MLOps를 실현하는 데 필요한 9가지 원칙을 도출함
- Figure 2는 이 원칙들을 시각화하고 각각이 어떤 구성 요소와 연결되는지를 보여줌
- CI/CD 자동화, 워크플로우 오케스트레이션, 재현성, 버전관리, 협업, 지속적인 ML학습 및 평가, ML 메타데이터 추적 및 로깅, 지속적 모니터링, 피드백 루프
![[MLOpsPrinciples.png | 600]]
## 4.2 Technical Components
1. CI/CD 구성 요소
	1. 빌드, 테스트, 제공, 배포 단계를 담당
	2. 특정 단계의 성공 또는 실패 여부를 개발자에게 빠르게 피드백하여 전체 생산성을 높임
	3. ex. Jenkins, GitHub Actions
2. 소스 코드 저장소
	1. 코드 저장과 버전 관리를 보장
	2. ex. Bitbucket, GitLab, GitHub
3. 워크플로우 오케스트레이션 구성 요소
	1. DAG(유향 비순환 그래프)를 사용하여 ML 워크플로우의 태스크를 오케스트레이션을 함
	2. DAG는 실행 순서와 각 단계에서 사용하는 아티팩트를 나타냄
	3. ex. Apache Airflow, Kubeflow Pipelines, AWS SageMaker Pipelines
4. 피처 저장소 시스템
	1. 공통적으로 사용되는 피처를 중앙에서 관리함
	2. 두 개의 데이터베이스로 구성
		1. 실험용으로 보통 지연 시간을 가지는 오프라인 저장소
		2. 프로덕션 환경에서 예측을 수행하기 위한 저지연 온라인 저장소
	3. ex. Google Feast, Amazon AWS Feature Store
5. 모델 학습 인프라
	1. 분산 또는 비분산 형태일 수 있으며, 일반적으로 확장 
	2. ex. Kubernetes, Red Hat OpenShift
6. 모델 레지스트리
	1. 학습된 ML 모델과 해당 메타데이터를 중앙에서 저장.
	2. 주요 기능: ML 아티팩트 저장 및 ML 메타데이터 저장
	3. ex. (고급 저장소)MLflow, AWS SageMaker (간단한 저장소) Microsoft Azure Storage, Google Cloud Storage, Amazon AWS S3
7. ML 메타데이터 저장소
	1. ML 워크플로우 파이프라인의 각 태스크에서 발생하는 다양한 메타데이터를 추적할 수 있도록 함.
	2. 또 다른 메타데이터 저장소는 모델 레지스트리 내부에 구성되어 각 학습 작업의 메타데이터, 모델 관련 메타데이터를 기록할 수 있음
	3. ex. Kubeflow Pipelines, AWS SageMaker Pipelines
8. 모델 서빙 구성 요소
	1. 다양한 목적에 맞게 설정 가능 (예: 온라인 추론, 배치 추론 등)
	2. 서빙은 REST API 등을 통해 제공될 수 있음.
	3. 기본 인프라 계층으로 확장 가능하고 분산된 모델 서빙 인프라를 권장함
	4. ex. Kubernetes와 Docker를 사용한 ML 모델 컨테이너화 및 Flask를 이용한 REST API 기반 서빙
		1. 기타 Kubernetes 지원 프레임워크: Kubeflow KServing
		2. 배치 예측을 위한 프레임워크: Apache Spark
		3. 클라우드 기반 서빙: Microsoft Azure ML REST API, AWS SageMaker Endpoints...
9. 모니터링 구성 요소
	1. 모델 서빙 성능의 지속적인 모니터링을 담당
	2. ML 인프라, CI/CD, 오케스트레이션의 모니터링
	3. ex. Prometheus + Gragana, ELK 스택, TensorBoard
		1. 내장 모니터링 기능이 있는 예시: Kubeflow, MLflow, AWS SageMaker Model Monitor 및 CloudWatch
## 4.3 Roles
![[MLOpsRoles.png | 400]]
- MLOps는 다양한 분야가 협력하는 프로세스로, 서로 다른 역할 간의 상호 작용이 ML 시스템을 설계, 관리, 자동화, 운영하는 데 필수적
- 다음은 각 역할, 그 목적, 관련된 주요 업무에 대한 간략한 설명임
1. 비즈니스 이해관계자
	1. ML을 통해 달성할 비즈니스 목표를 정의하고 비즈니스 관점에서의 커뮤니케이션을 담당
2. 솔루션 아키텍트
	1. 시스템 아키텍처를 설계하고 사용할 기술을 평가하여 결정하는 역할
3. 데이터 사이언티스트
	1. 비즈니스 문제를 ML 문제로 변환하고 모델 엔지니어링을 담당하며, 최적의 알고리즘과 하이퍼파리미터를 선택하는 역할
4. 데이터 엔지니어
	1. 데이터 및 피처 엔지니어링 파이프라인을 구축하고 관리하는 역할
	2. 피처 저장소 시스템의 데이터베이스로 적절하게 데이터를 수집할 수 있도록 보장
5. 소프트웨어 엔지니어
	1. 소프트웨어 설계 패턴, 널리 받아들여진 코딩 가이드라인, 베스트 프랙티스를 적용하여 ML 문제를 체계적으로 구축된 제품으로 변환하는 역할
6. DevOps 엔지니어
	1. 개발과 운영 간의 격차를 해소하는 역할을 하며, CI/CD 자동화, ML 워크플로우 오케스트레이션, 모델 배포, 모니터링을 보장함
7. ML 엔지니어 / MLOps 엔지니어
	1. ML 인프라를 구축 및 운영하고, 자동화된 ML 워크플로우 파이프라인을 관리
	2. 모델을 프로덕션 환경에 배포
	3. 모델 및 ML 인프라를 모니터링하는 업무를 수행
# 5. Architecture ans Workflow
![[MLOPsArchitecture&Workflow.png]]

- 위 사진은 일반적인 End-to-end MLOps 아키텍처. 다양한 단계에서 수행되는 작업들의 순서를 포함한 워크플로우도 함께 제시됨.
- MLOps 프로젝티 기획부터 모델 서빙까지 포함하며, 다음과 같은 네 단계로 구성됨
	- (A) MLOps 프로젝트 기획 (B) 피처 엔지니어링 파이프라인(데이터 수집 및 피처 저장소 적재 포함)
	- (C) 실험 과정 (D) 자동화된 ML 워크플로우 파이프라인 및 모델 서빙
### (A) MLOps 프로젝트 기획
### (B) 피처 엔지니어링 파이프라인
### (C) 실험 과정
### (D) 자동화된 ML 워크플로우 파이프라인 및 모델 서빙